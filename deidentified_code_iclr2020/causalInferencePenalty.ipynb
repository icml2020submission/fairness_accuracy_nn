{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "## Motivation\n",
    "This branch explores the use of concepts from Causal Inference for fairness penalties. \n",
    "This was inspired work on \n",
    "[debiasing word embeddings from Bolukbasi et.al](https://papers.nips.cc/paper/6228-man-is-to-computer-programmer-as-woman-is-to-homemaker-debiasing-word-embeddings.pdf) \n",
    "The basic idea of that paper is as follows. Each word is embedded according to some algorithm.\n",
    "This algorithm may be biased however, let's say according to gender.\n",
    "An intuitive way to debias the word embeddings is to first identify the gender subspace \n",
    "and then project embeddings onto the orthogonal complement of the gender subspace.\n",
    "The Bobulaski methodology heavily depends on the availability of pairs of words that differ only in gender.\n",
    "Supposing such a list exists, for example\n",
    "* {grandmother, grandfather}\n",
    "* {guy, gal}\n",
    "* {he, she}\n",
    "* {mother, father}\n",
    "\n",
    "Let $h$ denote the embedding of a word. Then if we form the differences\n",
    "* $h_{grandmother} - h_{grandfather}$\n",
    "* $h_{guy} - h_{gal}$\n",
    "* $h_{he} - h_{she}$\n",
    "* $h_{mother} - h_{father}$\n",
    "\n",
    "and conduct PCA on these differences, we can identify a gender subspace, \n",
    "let's call that $B$ defined by $k$ orthogonal unit vectors $b_1,\\ldots,b_k$. \n",
    "Let $h_B$ denote the projection of a vector $h$ onto the subspace $B$, i.e. $h_B = \\sum_{j=1}^k (v \\cdot b_j) b_j$.\n",
    "Then $h - h_B$ is the projection of $h$ onto the orthogonal complement of $B$.\n",
    "Bolukbasi et. al propse to debias word embeddings by projection onto the orthogonal complement of the identified gender subspace $B$. \n",
    "In otherwords, $h^{debiased} = h - h_B$.  \n",
    "\n",
    "## Causal Inference\n",
    "Going back to our debiasing neural network prediction project, there is a parallel between debiasing word embeddings and\n",
    "debiasing the internal representations in the neural networks. Let $h_i$ denote the hidden node vector for sample $i$ (ignore which layer this is, for now).\n",
    "Let $Z$ denote the sensitive attribute, assume it is binary for simplicity. \n",
    "Each sample also has a covariate vector $X$ associated to it. \n",
    "These are the variables that are used as input to the neural network predictor/classifier. \n",
    "Using the terminology and notation from the causal inference literature, \n",
    "let $h_i(1) := h_i(Z_i =1)$ be the potential representation for sample $i$ if the sensitive attribute is indeed $Z_i = 1$.\n",
    "Similarly, let $h_i(0):= h_i(Z_i=0)$ be the potential  representation if $Z_i = 0$. Both $h_i(1)$ and $h_i(0)$ can be \n",
    "thought of as random variables. Note that only one of them can ever be observed. \n",
    "So one of these potential outcomes is always a counterfactual and thus can never be observed.\n",
    "\n",
    "In an ideal situation, we would observe pairs $(h_i(1),h_i(0))$ and so would be able to apply the Bolukbasi methodology above. \n",
    "So in this branch, we try to figure out a way to circumvent this difficulty, i.e. the absence of pairs of observations that differ only in gender (or some other protected variable).   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "To demonstrate the idea, we need a dataset that has a binary sensitive attribute. We'll use the propublica compass data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiasing.debiasing_sweep(desired_seed=desired_seed, debias_type='causal_inference')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "stem_cell": {
   "cell_type": "raw",
   "source": "",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
